# asl_sign_language
A real-time Sign Language Detection system using deep learning and computer vision. Built with TensorFlow, OpenCV, and Python to recognize hand gestures and translate them into text.

**🚀 Features**

Real-time detection through webcam.

Deep learning-based gesture recognition using CNN.
Dataset preprocessing and model training in TensorFlow/Keras.
Easy-to-use Python implementation.
Can be extended for multiple sign languages.

**🛠️ Tech Stack**

Python
TensorFlow/Keras
OpenCV
NumPy & Pandas
Matplotlib/Seaborn (for visualization)

**📂 Project Workflow**

Data Collection – Preparing dataset of sign language images.
Preprocessing – Resizing, normalization, and augmentation of images.
Model Training – Building CNN architecture in TensorFlow/Keras.
Evaluation – Accuracy check and validation.
Deployment – Real-time gesture recognition using webcam.

**⚡ How to Run**

Clone the repository:
git clone https://github.com/chetassiddhu/asl_sign_language.git
Install dependencies:
pip install -r requirements.txt
Run the real-time detection script:
python detect_sign.py

**📈 Future Improvements**

Add support for more gestures.
Integrate with speech synthesis (convert detected signs into speech).
Deploy as a web/mobile app.
can be use for dumb people's interview or meating by useing webcam
